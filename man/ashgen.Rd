% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mengyin.R
\name{ashgen}
\alias{ashgen}
\title{Adaptive Shrinkage function for general deconvolution problem}
\usage{
ashgen(betahat, likelihood = c("normal", "t", "logF", "self-defined"),
  cdfFUN = NULL, pdfFUN = NULL, FUNargs = NULL, etruncFUN = NULL,
  method = c("fdr", "shrink"), mixcompdist = c("uniform", "halfuniform",
  "+uniform", "-uniform"), optmethod = c("mixIP", "cxxMixSquarem", "mixEM",
  "mixVBEM"), randomstart = FALSE, nullweight = 10, nonzeromode = FALSE,
  pointmass = NULL, prior = c("nullbiased", "uniform", "unit"),
  mixsd = NULL, gridmult = sqrt(2), outputlevel = 2, g = NULL,
  fixg = FALSE, cxx = NULL, VB = NULL, control = list())
}
\arguments{
\item{betahat}{a p vector of estimates}

\item{likelihood}{type of error distribution, can be normal ("normal"), 
generalized t ("t"), log-F ("logF") or self-defined distribution
("self-defined").}

\item{cdfFUN}{the CDF function of error distribution. 
Defaults for likelihood "normal", "t" and "logF" are "pnorm", 
"ptgen" and "plogf" respectively.}

\item{pdfFUN}{the PDF function of error distribution.
Defaults for likelihood "normal", "t" and "logF" are "dnorm", 
"dtgen" and "dlogf" respectively.}

\item{FUNargs}{a list of arguments passed to \code{cdfFUN} & \code{pdfFUN}. 
Each argument must be a scalar or a p vector corresponding to \code{betahat}.}

\item{etruncFUN}{(optional) the function to compute expectation of the truncated 
error distribution, which will be used for calculating \code{PosteriorMean}. 
The function should take \code{(a,b,...)}
as inputs and return expectation of truncated error distribution on (\code{a,b}) 
with distribution parameters \code{...}. Default method uses numerical integration
to compute the truncated mean.}

\item{method}{specifies how ash is to be run. Can be "shrinkage"
(if main aim is shrinkage) or "fdr" (if main aim is to assess
fdr or fsr) This is simply a convenient way to specify certain
combinations of parameters: "shrinkage" sets pointmass=FALSE
and prior="uniform"; "fdr" sets pointmass=TRUE and
prior="nullbiased".}

\item{mixcompdist}{distribution of components in mixture (
"uniform","halfuniform","normal" or "+uniform"), the default
value is "uniform" use "halfuniform" to allow for assymetric g,
and "+uniform"/"-uniform" to constrain g to be
positive/negative.}

\item{optmethod}{specifies optimization method used. Default is
"mixIP", an interior point method, if REBayes is installed;
otherwise an EM algorithm is used. The interior point method is
faster for large problems (n>2000).}

\item{randomstart}{logical, indicating whether to initialize EM
randomly. If FALSE, then initializes to prior mean (for EM
algorithm) or prior (for VBEM)}

\item{nullweight}{scalar, the weight put on the prior under
"nullbiased" specification, see \code{prior}}

\item{nonzeromode}{logical, indicating whether to use a non-zero
unimodal mixture(default is "FALSE")}

\item{pointmass}{logical, indicating whether to use a point mass at
zero as one of components for a mixture distribution}

\item{prior}{string, or numeric vector indicating Dirichlet prior
on mixture proportions (defaults to "uniform", or (1,1...,1);
also can be "nullbiased" (nullweight,1,...,1) to put more
weight on first component), or "unit" (1/K,...,1/K) [for
optmethod=mixVBEM version only]}

\item{mixsd}{vector of sds for underlying mixture components}

\item{gridmult}{the multiplier by which the default grid values for
mixsd differ by one another. (Smaller values produce finer
grids)}

\item{outputlevel}{determines amount of output [0=just fitted g;
1=also PosteriorMean and PosteriorSD (provided df=NULL - 
if df non-null, set outputlevel =3 to get these); 2= everything usually
needed; 3=also include results of mixture fitting procedure
(includes matrix of log-likelihoods used to fit mixture); 4=
output additional things required by flash (flash.data)]}

\item{g}{the prior distribution for beta (usually estimated from
the data; this is used primarily in simulated data to do
computations with the "true" g)}

\item{fixg}{if TRUE, don't estimate g but use the specified g -
useful for computations under the "true" g in simulations}

\item{cxx}{flag (deprecated, use optmethod) to indicate whether to
use the c++ (Rcpp) version. After application of Squared
extrapolation methods for accelerating fixed-point iterations
(R Package "SQUAREM"), the c++ version is no longer faster than
non-c++ version, thus we do not recommend using this one, and
might be removed at any point.}

\item{VB}{(deprecated, use optmethod) whether to use Variational
Bayes to estimate mixture proportions (instead of EM to find
MAP estimate), see \code{\link{mixVBEM}} and
\code{\link{mixEM}}}

\item{control}{A list of control parameters for the optmization
algorithm. Default value is set to be control.default=list(K =
1, method=3, square=TRUE, step.min0=1, step.max0=1, mstep=4,
kr=1, objfn.inc=1,tol=1.e-07, maxiter=5000, trace=FALSE). User
may supply changes to this list of parameter, say,
control=list(maxiter=10000,trace=TRUE)}
}
\value{
ashgen returns an object of \code{\link[base]{class}} "ash", a list with some or all of the following elements (determined by outputlevel) \cr
\item{fitted.g}{fitted mixture, either a normalmix or unimix}
\item{loglik}{log P(D|mle(pi))}
\item{logLR}{log[P(D|mle(pi))/P(D|beta==0)]}
\item{PosteriorMean}{A vector consisting the posterior mean of beta from the mixture}
\item{PosteriorSD}{A vector consisting the corresponding posterior standard deviation}
\item{PositiveProb}{A vector of posterior probability that beta is positive}
\item{NegativeProb}{A vector of posterior probability that beta is negative}
\item{ZeroProb}{A vector of posterior probability that beta is zero}
\item{lfsr}{The local false sign rate}
\item{lfdr}{A vector of estimated local false discovery rate}
\item{qvalue}{A vector of q values}
\item{call}{a call in which all of the specified arguments are specified by their full names}
\item{excludeindex}{the vector of index of observations with 0 standard error; if none, then returns NULL}
\item{optmethod}{the optimization method used}
\item{data}{a list consisting the input betahat and sebetahat (only included if outputlevel>2)}
}
\description{
Takes vectors of estimates (betahat) and the 
    error distribution parameters and applies shrinkage to them,
    using Empirical Bayes methods, to compute shrunk estimates for
    beta.
}
\details{
Suppose betahat=beta+e, where the errors e come from some error
    distribution with CDF & PDF provided, 
    we use Empirical methods to compute shrunk estimates for beta.
}
\examples{
beta = c(rep(0,100),rnorm(100))
sebetahat = abs(rnorm(200,0,1))
betahat = rnorm(200,beta,sebetahat)
#This is equivalent to running beta.ash=ash(betahat,sebetahat)
beta.ash = ashgen(betahat,likelihood="normal",FUNargs=list(sd=sebetahat))

#Suppose error distribution is Uniform(min=-2,max=2)
beta = c(rep(0,100),rnorm(100))
betahat = beta+runif(200,min=-2,max=2)
beta.ash = ashgen(betahat,"self-defined",cdfFUN="punif",pdfFUN="dunif",FUNargs=list(min=-2,max=2))

#Provide a self-defined function "etruncunif" to compute mean of
#uniform distribution Unif(min,max) truncated to range (a,b)
etruncunif = function(a,b,min,max){
  if(b<=min | a>=max){
    return(0)
  }else{
    return((max(a,min)+min(b,max))/2)
  }
}
beta.ash = ashgen(betahat,"self-defined",cdfFUN="punif",pdfFUN="dunif",
                  FUNargs=list(min=-2,max=2),etruncFUN="etruncunif")
}
\seealso{
\code{\link{ash.workhorse}} for complete specification of ash function

\code{\link{ashci}} for computation of credible intervals after getting the ash object return by \code{ash()}

\code{\link{ashm}} for Multi-model Adaptive Shrinkage function
}

