% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ash.R
\name{ash}
\alias{ash}
\alias{ash.workhorse}
\title{Adaptive Shrinkage}
\usage{
ash(betahat, sebetahat, mixcompdist = c("uniform", "halfuniform", "normal",
  "+uniform", "-uniform", "halfnormal"), df = NULL, ...)
}
\arguments{
\item{betahat}{a p vector of estimates}

\item{sebetahat}{a p vector of corresponding standard errors}

\item{mixcompdist}{distribution of components in mixture
("uniform","halfuniform" or "normal"; "halfnormal", "+uniform" or
"-uniform"), the default is "uniform". If you believe your effects
may be asymmetric, use "halfuniform" or "halfnormal". If you want
to allow only positive/negative effects use "+uniform"/"-uniform".
The use of "normal" and "halfnormal" is permitted only if df=NULL.}

\item{df}{appropriate degrees of freedom for (t) distribution of
betahat/sebetahat, default is NULL which is actually treated as
infinity (Gaussian)}

\item{...}{Further arguments of function \code{ash} to be passed to
\code{\link{ash.workhorse}}.}

\item{method}{specifies how ash is to be run. Can be "shrinkage"
(if main aim is shrinkage) or "fdr" (if main aim is to assess fdr
or fsr) This is simply a convenient way to specify certain
combinations of parameters: "shrinkage" sets pointmass=FALSE and
prior="uniform"; "fdr" sets pointmass=TRUE and prior="nullbiased".}

\item{optmethod}{specifies the function implementing an
optimization method. Default is "mixIP", an interior point method,
if REBayes is installed; otherwise an EM algorithm is used. The
interior point method is faster for large problems (n>2000),
particularly when method="shrink".}

\item{nullweight}{scalar, the weight put on the prior under
"nullbiased" specification, see \code{prior}}

\item{mode}{either numeric (indicating mode of g) or string
"estimate", to indicate mode should be estimated, or a two
dimension numeric vector to indicate the interval to be searched
for the mode.}

\item{pointmass}{Logical, indicating whether to use a point mass at
zero as one of components for a mixture distribution.}

\item{prior}{string, or numeric vector indicating Dirichlet prior
on mixture proportions (defaults to "uniform", or (1,1...,1); also
can be "nullbiased" (nullweight,1,...,1) to put more weight on
first component), or "unit" (1/K,...,1/K) [for optmethod=mixVBEM
version only].}

\item{mixsd}{Vector of sds for underlying mixture components.}

\item{gridmult}{the multiplier by which the default grid values for
mixsd differ by one another. (Smaller values produce finer grids.)}

\item{outputlevel}{determines amount of output. There are several
numeric options [0=just fitted g; 1=also PosteriorMean and
PosteriorSD; 2= everything usually needed; 3=also include results
of mixture fitting procedure (includes matrix of log-likelihoods
used to fit mixture); 4=output additional things required by flash
(flash_data)]. Otherwise the user can also specify the output they
require in detail (see Examples).}

\item{g}{The prior distribution for beta (usually estimated from
the data; this is used primarily in simulated data to do
computations with the "true" g).}

\item{fixg}{If TRUE, don't estimate g but use the specified g -
useful for computations under the "true" g in simulations.}

\item{alpha}{Numeric value of alpha parameter in the model.}

\item{grange}{Two dimension numeric vector indicating the left and
right limit of the prior g. Default is c(-Inf, Inf).}

\item{control}{A list of control parameters passed to optmethod.}

\item{lik}{Contains details of the likelihood used; for general
ash. Currently, the following choices are allowed: normal (see
function lik_normal(); binomial likelihood (see function
lik_binom); likelihood based on logF error distribution (see
function lik_logF); mixture of normals likelihood (see function
lik_normalmix); and Poisson likelihood (see function lik_pois).}

\item{weights}{a vector of weights for observations; use with
optmethod = "w_mixEM"; this is currently beta-functionality.}
}
\value{
ash returns an object of \code{\link[base]{class}} "ash", a
list with some or all of the following elements (determined by
outputlevel) \cr
\item{fitted_g}{fitted mixture}
\item{loglik}{log P(D|fitted_g)}
\item{logLR}{log[P(D|fitted_g)/P(D|beta==0)]}
\item{result}{A dataframe whose columns are:}
\describe{
  \item{NegativeProb}{A vector of posterior probability that beta is
    negative.}
  \item{PositiveProb}{A vector of posterior probability that beta is
    positive.}
  \item{lfsr}{A vector of estimated local false sign rate.}
  \item{lfdr}{A vector of estimated local false discovery rate.}
  \item{qvalue}{A vector of q values.}
  \item{svalue}{A vector of s values.}
  \item{PosteriorMean}{A vector consisting the posterior mean of beta
    from the mixture.}
  \item{PosteriorSD}{A vector consisting the corresponding posterior
    standard deviation.}
  }
\item{call}{a call in which all of the specified arguments are
  specified by their full names}
\item{data}{a list containing details of the data and models
  used (mostly for internal use)}
\item{fit_details}{a list containing results of mixture optimization,
  and matrix of component log-likelihoods used in this optimization}
}
\description{
Takes vectors of estimates (betahat) and their
standard errors (sebetahat), together with degrees of freedom (df)
and applies shrinkage to them, using Empirical Bayes methods, to
compute shrunk estimates for beta. Most users will be happy with
the ash function, which provides the same usage, but has a simpler
interface.
}
\details{
See README for more details.
}
\examples{
beta = c(rep(0,100),rnorm(100))
sebetahat = abs(rnorm(200,0,1))
betahat = rnorm(200,beta,sebetahat)
beta.ash = ash(betahat, sebetahat)
names(beta.ash)
head(beta.ash$result) # the main dataframe of results
head(get_pm(beta.ash)) # get_pm returns posterior mean
head(get_lfsr(beta.ash)) # get_lfsr returns the local false sign rate
graphics::plot(betahat,get_pm(beta.ash),xlim=c(-4,4),ylim=c(-4,4))

CIMatrix=ashci(beta.ash,level=0.95)
print(CIMatrix)

# Illustrating the non-zero mode feature.
betahat=betahat+5
beta.ash = ash(betahat, sebetahat)
graphics::plot(betahat,get_pm(beta.ash))
betan.ash=ash(betahat, sebetahat,mode=5)
graphics::plot(betahat,get_pm(betan.ash))
summary(betan.ash)

# Running ash with different error models
beta.ash1 = ash(betahat, sebetahat, lik = lik_normal())
beta.ash2 = ash(betahat, sebetahat, lik = lik_t(df=4))

e = rnorm(100)+log(rf(100,df1=10,df2=10)) # simulated data with log(F) error
e.ash = ash(e,1,lik=lik_logF(df1=10,df2=10))

# Specifying the output
beta.ash = ash(betahat, sebetahat, output = c("fitted_g","logLR","lfsr"))

#Running ash with a pre-specified g, rather than estimating it
beta = c(rep(0,100),rnorm(100))
sebetahat = abs(rnorm(200,0,1))
betahat = rnorm(200,beta,sebetahat)
true_g = normalmix(c(0.5,0.5),c(0,0),c(0,1)) # define true g
## Passing this g into ash causes it to i) take the sd and the means
## for each component from this g, and ii) initialize pi to the value
## from this g.
beta.ash = ash(betahat, sebetahat,g=true_g,fixg=TRUE)

# running with weights
beta.ash = ash(betahat, sebetahat, optmethod="w_mixEM",
               weights = c(rep(0.5,100),rep(1,100)))

}
\seealso{
\code{\link{ashci}} for computation of credible intervals
after getting the ash object return by \code{ash()}
}
